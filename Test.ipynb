{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 784])\n",
      "torch.Size([7, 256])\n",
      "torch.Size([7, 256])\n",
      "torch.Size([7, 784])\n"
     ]
    }
   ],
   "source": [
    "# ! python main.py evaluation --batch_size=128\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from data.dataset import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchnet import meter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "class VAE:\n",
    "    def __init__(self, in_dim, encoder_width, decoder_width, latent_dim, device=torch.device('cpu')):\n",
    "        # device\n",
    "        self.name = 'VAE'\n",
    "        self.device = device\n",
    "        \n",
    "        # initialize encoder/decoder weights and biases\n",
    "        self.weights, self.biases = self.init_vae_params(in_dim, encoder_width, decoder_width, latent_dim)\n",
    "        \n",
    "        # build the VAE model\n",
    "        \n",
    "        X = torch.randn(7,784)\n",
    "        print(X.size())\n",
    "        \n",
    "        z_mean, z_std = self._encoding(X, self.weights, self.biases)\n",
    "        \n",
    "        print(z_mean.size())\n",
    "        print(z_std.size())\n",
    "        \n",
    "        Xstar = self._decoding(z_mean, self.weights, self.biases)\n",
    "        \n",
    "        print(Xstar.size())\n",
    "        \n",
    "    def _encoding(self, X, weights, biases):\n",
    "        # Kingma Supplemtary C.2\n",
    "        output = torch.matmul(X, weights['encoder_hidden']) + biases['encoder_hidden']\n",
    "        output = torch.tanh(output) \n",
    "        mean_output = torch.matmul(output, weights['latent_mean']) + biases['latent_mean']\n",
    "        std_output = torch.matmul(output, weights['latent_std']) + biases['latent_std']\n",
    "        \n",
    "        return mean_output, std_output\n",
    "        \n",
    "    def _decoding(self, Z, weights, biases):\n",
    "        output = torch.matmul(Z, weights['decoder_hidden']) + biases['decoder_hidden']\n",
    "        output = torch.tanh(output)\n",
    "        Xstar = torch.matmul(output, weights['decoder_out']) + biases['decoder_out']\n",
    "        \n",
    "        return Xstar\n",
    "        \n",
    "        \n",
    "\n",
    "#         # config learnable variables\n",
    "#         self.activation = {'relu':F.relu, 'sigmoid': torch.sigmoid, 'tanh': F.tanh}[activation]            \n",
    "#         self.weights, self.biases = self.init_nn_weights()\n",
    "        \n",
    "#         # config dataset\n",
    "#         mnist = MNIST()\n",
    "#         self.train_data = mnist.get(train=True) \n",
    "#         self.test_data = mnist.get(train=False)\n",
    "        \n",
    "#         self.criterion = torch.nn.CrossEntropyLoss()                 \n",
    "\n",
    "    def init_vae_params(self, in_dim, encoder_width, decoder_width, latent_dim):\n",
    "        \n",
    "        weights = {\n",
    "            'encoder_hidden': self.xavier_init(in_dim, encoder_width),\n",
    "            'latent_mean': self.xavier_init(encoder_width, latent_dim),\n",
    "            'latent_std' : self.xavier_init(encoder_width, latent_dim),\n",
    "            'decoder_hidden': self.xavier_init(latent_dim, decoder_width),\n",
    "            'decoder_out': self.xavier_init(decoder_width, in_dim),\n",
    "        }\n",
    "        \n",
    "        biases = {\n",
    "            'encoder_hidden': self.xavier_init(1, encoder_width),\n",
    "            'latent_mean': self.xavier_init(1, latent_dim),\n",
    "            'latent_std' : self.xavier_init(1, latent_dim),\n",
    "            'decoder_hidden': self.xavier_init(1, decoder_width),\n",
    "            'decoder_out': self.xavier_init(1, in_dim),\n",
    "        }\n",
    "            \n",
    "        return weights, biases\n",
    "    \n",
    "    def xavier_init(self, in_d, out_d):\n",
    "        xavier_stddev = np.sqrt(2.0/(in_d + out_d))\n",
    "        W = torch.normal(size=(in_d, out_d), mean=0.0, std=xavier_stddev, requires_grad=True, device=self.device)\n",
    "        return W\n",
    "    \n",
    "    \n",
    "model = VAE(784, 512, 512, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
